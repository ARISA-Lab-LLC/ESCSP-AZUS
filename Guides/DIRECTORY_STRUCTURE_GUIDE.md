# AZUS Directory Structure Guide

**Version:** 2.0 (Feb 25, 2026)  
**Reflects:** Post-Prefect standalone refactor

---

## Project Root Structure

```
azus/
â”œâ”€â”€ Guides/                              â† Documentation and how-to guides
â”‚   â”œâ”€â”€ CITATIONS_USER_GUIDE.md
â”‚   â”œâ”€â”€ CSV_FIX_GUIDE.md
â”‚   â”œâ”€â”€ DIRECTORY_STRUCTURE_GUIDE.md     â† This file
â”‚   â”œâ”€â”€ PREFECT_VS_STANDALONE.md
â”‚   â”œâ”€â”€ REFACTORING_CHANGELOG.md
â”‚   â”œâ”€â”€ STANDALONE_README.md
â”‚   â””â”€â”€ TEST_UPLOAD_GUIDE.md
â”‚
â”œâ”€â”€ models/                              â† Pydantic data models (no editing needed)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ audiomoth.py                     â† DataCollector, UploadData, DraftConfig
â”‚   â””â”€â”€ invenio.py                       â† Zenodo metadata models
â”‚
â”œâ”€â”€ Records/                             â† Upload result logs (auto-created)
â”‚   â”œâ”€â”€ successful_results.csv           â† Created on first successful upload
â”‚   â””â”€â”€ failed_results.csv              â† Created on first failed upload
â”‚
â”œâ”€â”€ Resources/                           â† Config, templates, shared data files
â”‚   â”œâ”€â”€ project_config.json              â† Project identity (creators, funding, etc.)
â”‚   â”œâ”€â”€ config.json                      â† Upload configuration (YOU CREATE THIS)
â”‚   â”œâ”€â”€ set_env.sh                       â† API credentials (YOU CREATE THIS)
â”‚   â”œâ”€â”€ README_template.html             â† Template for Zenodo record descriptions
â”‚   â”œâ”€â”€ related_identifiers.csv          â† Global citations/related works (optional)
â”‚   â”œâ”€â”€ references.csv                   â† Global bibliography (optional)
â”‚   â”œâ”€â”€ collectors.csv                   â† Collector metadata spreadsheet
â”‚   â”œâ”€â”€ 2023_Annular_Zenodo_Form_Spreadsheet.csv
â”‚   â”œâ”€â”€ 2024_Total_Zenodo_Form_Spreadsheet.csv
â”‚   â”œâ”€â”€ CONFIG_data_dict.csv             â† Data dictionary for CONFIG.TXT fields
â”‚   â”œâ”€â”€ WAV_data_dict.csv                â† Data dictionary for WAV file fields
â”‚   â”œâ”€â”€ file_list_data_dict.csv          â† Data dictionary for file_list.csv
â”‚   â”œâ”€â”€ file_list_Template.csv           â† Template for file manifests
â”‚   â”œâ”€â”€ License.txt                      â† CC BY 4.0 license text
â”‚   â”œâ”€â”€ AudioMoth_Operation_Manual.pdf   â† Uploaded to each Zenodo record
â”‚   â””â”€â”€ set_env.sh.example               â† Safe template (no real credentials)
â”‚
â”œâ”€â”€ Staging_Area/                        â† Prepared datasets ready for upload
â”‚   â””â”€â”€ ESID_XXX/                        â† One subdirectory per dataset
â”‚       â””â”€â”€ ... (see Staging Area section below)
â”‚
â”œâ”€â”€ templates/                           â† .example files for new project setup
â”‚   â”œâ”€â”€ config.json.example
â”‚   â”œâ”€â”€ project_config.json.example
â”‚   â”œâ”€â”€ README_template.html.example
â”‚   â”œâ”€â”€ related_identifiers.csv.example
â”‚   â”œâ”€â”€ references.csv.example
â”‚   â””â”€â”€ set_env.sh.example
â”‚
â”œâ”€â”€ standalone_tasks.py                  â† MAIN ENTRY POINT
â”œâ”€â”€ standalone_uploader.py               â† Zenodo API client
â”œâ”€â”€ prepare_dataset.py                   â† Dataset preparation script
â”œâ”€â”€ requirements-standalone.txt          â† Python dependencies
â””â”€â”€ README.md
```

> âš ï¸ **`Resources/config.json` and `Resources/set_env.sh` are NOT included in the
> repository** â€” they contain personal paths and API credentials. Create them from
> the `.example` templates in `templates/`.

---

## Staging Area Structure

Each dataset lives in its own self-contained subdirectory. The upload script
scans for `ESID_XXX/` subdirectories and processes each one independently.

```
Staging_Area/
â”œâ”€â”€ ESID_004/
â”‚   â”œâ”€â”€ ESID_004.zip                     â† Audio archive (WAV files + CONFIG.TXT)
â”‚   â”œâ”€â”€ ESID_004_to_upload.csv           â† Upload manifest (what Zenodo receives)
â”‚   â”œâ”€â”€ README.html                      â† Zenodo description (NOT uploaded as file)
â”‚   â”œâ”€â”€ README.md                        â† Uploaded to Zenodo
â”‚   â”œâ”€â”€ file_list.csv                    â† File manifest with SHA-512 hashes
â”‚   â”œâ”€â”€ total_eclipse_data.csv           â† Site metadata for this ESID
â”‚   â”œâ”€â”€ total_eclipse_data_data_dict.csv â† Data dictionary for above
â”‚   â”œâ”€â”€ CONFIG_data_dict.csv
â”‚   â”œâ”€â”€ WAV_data_dict.csv
â”‚   â”œâ”€â”€ file_list_data_dict.csv
â”‚   â”œâ”€â”€ AudioMoth_Operation_Manual.pdf
â”‚   â””â”€â”€ License.txt
â”‚
â”œâ”€â”€ ESID_005/
â”‚   â””â”€â”€ ... (same structure)
â”‚
â””â”€â”€ ESID_006/
    â””â”€â”€ ... (same structure)
```

### File roles at a glance

| File | Uploaded to Zenodo | Purpose |
|------|--------------------|---------|
| `ESID_XXX.zip` | Yes | All WAV recordings + CONFIG.TXT |
| `ESID_XXX_to_upload.csv` | No | Tells AZUS which files to upload |
| `README.html` | No | Content becomes the Zenodo description field |
| `README.md` | Yes | Human-readable documentation |
| `file_list.csv` | Yes | Complete file listing with SHA-512 hashes |
| `total_eclipse_data.csv` | Yes | Single-row site metadata |
| `*_data_dict.csv` | Yes | Data dictionaries |
| `AudioMoth_Operation_Manual.pdf` | Yes | Device documentation |
| `License.txt` | Yes | CC BY 4.0 license |

### ZIP archive contents

```
ESID_004.zip contains:
â”œâ”€â”€ 20240408_120000.WAV
â”œâ”€â”€ 20240408_120500.WAV
â”œâ”€â”€ ... (all WAV files)
â””â”€â”€ CONFIG.TXT
```

### Upload manifest format

```csv
File Name
ESID_004.zip
README.md
file_list.csv
total_eclipse_data.csv
total_eclipse_data_data_dict.csv
CONFIG_data_dict.csv
WAV_data_dict.csv
file_list_data_dict.csv
AudioMoth_Operation_Manual.pdf
License.txt
```

`README.html` is deliberately excluded â€” its content is used as the Zenodo
description field, not uploaded as a file.

---

## Complete Workflow

### Step 1: Raw Data

Start with your raw AudioMoth data:

```
Raw_Data/
â””â”€â”€ ESID#004/
    â”œâ”€â”€ 20240408_120000.WAV
    â”œâ”€â”€ 20240408_120500.WAV
    â”œâ”€â”€ ... (all WAV files)
    â””â”€â”€ CONFIG.TXT                       â† Generated by AudioMoth device
```

> âš ï¸ `CONFIG.TXT` is generated automatically by the AudioMoth device and will
> be present in any genuine AudioMoth recording folder. Do not create it manually.

---

### Step 2: Prepare Dataset

`prepare_dataset.py` does all the work in one step â€” creates the ZIP, generates
README.html from the template, creates the upload manifest, and assembles all
metadata files.

```bash
python prepare_dataset.py Raw_Data/ESID#004 \
    --collector-csv Resources/collectors.csv \
    --eclipse-type total \
    --output-dir Staging_Area/ESID_004
```

> âš ï¸ Your collector CSV **must use the current column headers** exactly.
> `prepare_dataset.py` validates headers before processing and will print a
> clear error listing missing columns if the format is wrong.
> See `Guides/CSV_FIX_GUIDE.md` for the column mapping from older formats.

**What gets created:**
```
Staging_Area/
â””â”€â”€ ESID_004/
    â”œâ”€â”€ ESID_004.zip                     â† Created (WAV files + CONFIG.TXT)
    â”œâ”€â”€ ESID_004_to_upload.csv           â† Created (upload manifest)
    â”œâ”€â”€ README.html                      â† Generated from README_template.html
    â”œâ”€â”€ README.md                        â† Generated from README.html
    â”œâ”€â”€ file_list.csv                    â† Generated (SHA-512 hashes of all files)
    â”œâ”€â”€ total_eclipse_data.csv           â† Generated (single-row metadata)
    â”œâ”€â”€ total_eclipse_data_data_dict.csv â† Copied from Resources/
    â”œâ”€â”€ CONFIG_data_dict.csv             â† Copied from Resources/
    â”œâ”€â”€ WAV_data_dict.csv                â† Copied from Resources/
    â”œâ”€â”€ file_list_data_dict.csv          â† Copied from Resources/
    â”œâ”€â”€ AudioMoth_Operation_Manual.pdf   â† Copied from Resources/
    â””â”€â”€ License.txt                      â† Copied from Resources/
```

> There is no separate `create_upload_package.py` step. `prepare_dataset.py`
> handles everything including ZIP creation and manifest generation.

---

### Step 3: Configure

`Resources/config.json` uses a `datasets` list â€” one entry per batch of datasets:

```json
{
    "project_config": "Resources/project_config.json",
    "readme_template": "Resources/README_template.html",

    "uploads": {
        "datasets": [
            {
                "name": "2024 Total Eclipse",
                "dataset_dir": "/path/to/Staging_Area",
                "collectors_csv": "/path/to/Resources/collectors.csv",
                "dataset_category": "Total"
            }
        ],
        "related_identifiers_csv": "Resources/related_identifiers.csv",
        "references_csv": "Resources/references.csv",
        "successful_results_file": "Records/successful_results.csv",
        "failure_results_file": "Records/failed_results.csv",
        "delete_failures": false,
        "auto_publish": false
    }
}
```

**`dataset_dir` points to `Staging_Area/`** (the parent of ESID subdirectories),
not to any individual `ESID_XXX/` folder.

> âš ï¸ **Old format no longer supported.** The previous `"total": {...}` and
> `"annular": {...}` keys have been replaced by the `"datasets": [...]` list.
> Multiple dataset categories are handled by adding additional entries to the list.

---

### Step 4: Upload

```bash
# Load credentials
source Resources/set_env.sh

# Dry run first â€” validates config and credentials (no network calls to Zenodo)
python standalone_tasks.py --config Resources/config.json --dry-run

# Actual upload (runs Zenodo connection check, then prompts for confirmation)
python standalone_tasks.py --config Resources/config.json
```

AZUS automatically runs a **Zenodo connection check** before uploading â€”
verifying both connectivity and write permissions using a minimal test draft
that is immediately deleted. If the check fails, a detailed error report is
printed and the upload is aborted cleanly.

**What happens during upload:**
1. Credentials loaded from environment variables
2. Zenodo connectivity and write-permission verified
3. Each `ESID_XXX/` subdirectory in `dataset_dir` is discovered
4. `ESID_XXX_to_upload.csv` manifest is read for each dataset
5. All listed files are verified present before any upload begins
6. Draft record created on Zenodo with full metadata
7. Files uploaded one by one
8. Results saved to `Records/successful_results.csv` or `failed_results.csv`
9. Uploaded ZIPs tracked in `.uploaded_files.txt` to prevent re-uploads on re-runs

---

## File Discovery Logic

```
standalone_tasks.py scans dataset_dir
    â”‚
    â”œâ”€â”€ finds ESID_XXX/ subdirectories
    â”‚       â”‚
    â”‚       â”œâ”€â”€ looks for ESID_XXX_to_upload.csv  (manifest)
    â”‚       â”‚       â””â”€â”€ if found: uploads exactly the files listed
    â”‚       â”‚
    â”‚       â””â”€â”€ if no manifest: falls back to default_required_files
    â”‚               from Resources/project_config.json
    â”‚
    â””â”€â”€ skips any ESID whose ZIP is already in .uploaded_files.txt
```

---

## Citations â€” Global vs Per-Record

`related_identifiers.csv` and `references.csv` can be specified globally in
`config.json` (applies the same citations to every record in the batch):

```json
"related_identifiers_csv": "Resources/related_identifiers.csv",
"references_csv": "Resources/references.csv"
```

> ğŸ”œ **Coming soon:** Per-record citation override. Place
> `related_identifiers.csv` and/or `references.csv` directly inside an
> `ESID_XXX/` staging directory to override the global files for that record.
> If no per-record file is found, AZUS falls back to the global config paths.

---

## Common Structural Errors

### WRONG â€” ZIP in parent directory

```
Staging_Area/
â”œâ”€â”€ ESID_005.zip              â† Wrong â€” must be inside ESID_005/
â””â”€â”€ ESID_005/
    â””â”€â”€ README.html
```

### WRONG â€” Flat structure (no subdirectories)

```
Staging_Area/
â”œâ”€â”€ ESID_005.zip
â”œâ”€â”€ README.md
â””â”€â”€ file_list.csv
```

### WRONG â€” Old config format

```json
"uploads": {
    "total": { "dataset_dir": "..." }    â† Old format â€” no longer supported
}
```

### CORRECT â€” Subdirectory structure

```
Staging_Area/
â””â”€â”€ ESID_005/
    â”œâ”€â”€ ESID_005.zip
    â”œâ”€â”€ ESID_005_to_upload.csv
    â””â”€â”€ ... (all files together)
```

### CORRECT â€” New config format

```json
"uploads": {
    "datasets": [
        {
            "name": "2024 Total Eclipse",
            "dataset_dir": "/path/to/Staging_Area",
            "collectors_csv": "/path/to/collectors.csv",
            "dataset_category": "Total"
        }
    ]
}
```

---

## Verification Commands

```bash
# List all ESID directories in staging
ls -d Staging_Area/ESID_*/

# Confirm each has a ZIP and manifest
ls Staging_Area/ESID_*/ESID_*.zip
ls Staging_Area/ESID_*/ESID_*_to_upload.csv

# Inspect one dataset
ls -lh Staging_Area/ESID_004/
cat Staging_Area/ESID_004/ESID_004_to_upload.csv

# Verify ZIP contents
unzip -l Staging_Area/ESID_004/ESID_004.zip | head -20

# Validate JSON config syntax before running
python3 -c "import json; json.load(open('Resources/config.json'))" && echo "Valid JSON"

# Dry run â€” validates config and credentials
python standalone_tasks.py --config Resources/config.json --dry-run
```

---

## Batch Processing

Prepare multiple ESID directories, then upload all in one run:

```bash
# Prepare each dataset
python prepare_dataset.py Raw_Data/ESID#004 --collector-csv Resources/collectors.csv \
    --eclipse-type total --output-dir Staging_Area/ESID_004
python prepare_dataset.py Raw_Data/ESID#005 --collector-csv Resources/collectors.csv \
    --eclipse-type total --output-dir Staging_Area/ESID_005

# Upload all â€” AZUS processes every ESID_XXX/ subdirectory automatically
python standalone_tasks.py --config Resources/config.json
```

Already-uploaded ZIPs are tracked in `.uploaded_files.txt` and skipped on re-runs.

---

## Summary

- **`prepare_dataset.py`** handles ZIP creation, manifest, README, and metadata in one step
- **Each ESID** has its own self-contained subdirectory in `Staging_Area/`
- **`dataset_dir`** in config points to `Staging_Area/` (parent), not individual ESID folders
- **Entry point** is `standalone_tasks.py` â€” not `standalone_upload.py`
- **Config format** uses `"datasets": [...]` list â€” not `"total":` / `"annular":` keys
- **Zenodo connection** is verified automatically before any upload attempt
- **Credentials** live in `Resources/set_env.sh` â€” never hardcoded anywhere
