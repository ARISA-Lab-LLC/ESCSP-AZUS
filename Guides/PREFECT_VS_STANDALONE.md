# AZUS: Prefect vs Standalone - Which Should You Use?

## Quick Decision Guide

**Use Standalone if:**
- âœ… You want simple, direct uploads without extra setup
- âœ… You don't need a web dashboard
- âœ… You're comfortable with command-line tools
- âœ… You want to avoid running a server
- âœ… You're doing one-time or infrequent uploads

**Use Prefect if:**
- âœ… You want a visual web dashboard
- âœ… You need detailed flow visualization
- âœ… You want to schedule recurring uploads
- âœ… You need to pause/resume workflows
- âœ… You're managing complex, multi-step pipelines
- âœ… Multiple people need to monitor uploads

## Feature Comparison

### Setup & Requirements

| Feature | Standalone | Prefect |
|---------|-----------|---------|
| Python version | 3.9+ | 3.9+ |
| Prefect server | âŒ Not needed | âœ… Required |
| Port 4200 | âŒ Not used | âœ… Must be available |
| Virtual environment | âœ… Required | âœ… Required |
| Environment variables | âœ… Required | âœ… Required |
| Setup time | ~5 minutes | ~15-20 minutes |

### Upload Features

| Feature | Standalone | Prefect |
|---------|-----------|---------|
| Upload to Zenodo | âœ… Yes | âœ… Yes |
| Batch uploads | âœ… Sequential | âœ… Sequential or parallel |
| Resume after failure | âœ… Automatic (file tracking) | âœ… Automatic (block tracking) |
| Duplicate prevention | âœ… File-based | âœ… Block-based |
| Progress tracking | âœ… Console output | âœ… Web dashboard |
| Error reporting | âœ… Console + log file | âœ… Dashboard + logs |

### Monitoring & Debugging

| Feature | Standalone | Prefect |
|---------|-----------|---------|
| Real-time console output | âœ… Yes | âš ï¸ Limited |
| Log file | âœ… azus_upload.log | âœ… Prefect logs |
| Web dashboard | âŒ No | âœ… Yes |
| Flow visualization | âŒ No | âœ… Yes |
| Historical runs | âš ï¸ Log files only | âœ… Full history |
| Alerts/notifications | âŒ No | âœ… Configurable |

### Performance

| Feature | Standalone | Prefect |
|---------|-----------|---------|
| Upload speed | Same | Same |
| Memory usage | Low | Medium |
| CPU usage | Low | Low-Medium |
| Concurrent uploads | âŒ Sequential only | âœ… Configurable |
| File tracking overhead | Minimal | Low |

## Detailed Comparison

### Installation

**Standalone:**
```bash
# 1. Activate environment
source prefect-env/bin/activate

# 2. Install extra dependency
pip install requests

# 3. Set credentials
source set_env.sh

# 4. Done! Ready to upload
python standalone_upload.py
```

**Prefect:**
```bash
# 1. Activate environment
source prefect-env/bin/activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Set credentials
source set_env.sh

# 4. Create concurrency limit
prefect gcl create rate-limit:invenio-rdm-api --limit 5 --slot-decay-per-second 1.0

# 5. Start Prefect server (keep running)
prefect server start

# 6. In another terminal, create deployment
python uploads.py

# 7. Run via dashboard or CLI
# (Navigate to localhost:4200)
```

### Running Uploads

**Standalone:**
```bash
# Simple one-liner
python standalone_upload.py

# With options
python standalone_upload.py --dry-run
python standalone_upload.py --config /path/to/config.json
```

**Prefect:**
```bash
# Option 1: Via web dashboard
# - Open http://localhost:4200
# - Navigate to Deployments
# - Click "upload-datasets-deployment"
# - Click "Run" â†’ "Quick run"

# Option 2: Via CLI
prefect deployment run upload-datasets/upload-datasets-deployment
```

### Monitoring Progress

**Standalone:**
```bash
# Watch console output
python standalone_upload.py

# Output shows real-time progress:
ğŸ“¦ Processing 1/30: ESID 004
ğŸš€ Starting upload for ESID 004
  [1/12] Uploading ESID_004.zip (245.3 MB)...
  âœ… Uploaded in 45.2s
  [2/12] Uploading README.md (0.05 MB)...
  âœ… Uploaded in 1.2s

# Monitor log file in another terminal
tail -f azus_upload.log
```

**Prefect:**
```bash
# Web dashboard at http://localhost:4200
# Shows:
# - Flow run status
# - Task completion
# - Timeline view
# - Logs tab
# - Error details

# CLI monitoring
prefect flow-run ls
prefect flow-run logs <flow-run-id>
```

### Error Handling

**Standalone:**
```
If upload fails:
1. Error shown in console immediately
2. Details logged to azus_upload.log
3. Failed result saved to CSV
4. Script continues with next dataset
5. Summary shows failures at end
```

**Prefect:**
```
If upload fails:
1. Task marked as failed in dashboard
2. Error details in flow run logs
3. Failed result saved to CSV
4. Flow continues with next dataset
5. Dashboard shows overall status
```

### Resuming Interrupted Uploads

**Standalone:**
```bash
# If interrupted (Ctrl+C, crash, etc.):
# 1. .uploaded_files.txt tracks completed uploads
# 2. Simply run again:
python standalone_upload.py

# Already uploaded files automatically skipped
```

**Prefect:**
```bash
# If interrupted:
# 1. Prefect block tracks completed uploads
# 2. Create new flow run:
# - Via dashboard: Click "Run" on deployment
# - Via CLI: prefect deployment run ...

# Already uploaded files automatically skipped
```

### Checking Upload Status

**Standalone:**
```bash
# View uploaded files
cat .uploaded_files.txt

# Count uploads
wc -l .uploaded_files.txt

# Check results
cat successful_results.csv
cat failed_results.csv

# View logs
tail -100 azus_upload.log
```

**Prefect:**
```bash
# Web dashboard:
# - Go to Flow Runs
# - View completed runs
# - Check individual task statuses

# CLI:
prefect flow-run ls --limit 10
prefect block ls

# Results CSVs (same as standalone):
cat successful_results.csv
cat failed_results.csv
```

## Use Cases

### Use Case 1: One-Time Bulk Upload

**Scenario:** Upload 200 datasets once

**Recommendation:** Standalone â­
- Simpler setup
- Less overhead
- Direct execution
- Easy to monitor

**Command:**
```bash
python standalone_upload.py
```

### Use Case 2: Regular Weekly Uploads

**Scenario:** Upload new datasets every week

**Recommendation:** Prefect â­
- Can schedule runs
- Web dashboard for team
- Historical tracking
- Better for recurring tasks

**Setup:**
```bash
# Create schedule in Prefect
# Monitor via dashboard
```

### Use Case 3: Testing/Development

**Scenario:** Testing upload pipeline with sample data

**Recommendation:** Standalone â­
- Quick iterations
- No server overhead
- Easier debugging
- Faster feedback

**Command:**
```bash
python standalone_upload.py --dry-run
```

### Use Case 4: Production Deployments

**Scenario:** Production system with monitoring

**Recommendation:** Prefect â­
- Professional dashboard
- Better error tracking
- Team visibility
- Alerting capabilities

### Use Case 5: Single User, Infrequent Uploads

**Scenario:** Individual researcher uploading data occasionally

**Recommendation:** Standalone â­
- Minimal setup
- No server to maintain
- Simple workflow
- Direct control

## Migration Path

### From Prefect to Standalone

1. Stop Prefect server
2. Copy these files to your AZUS directory:
   - `standalone_upload.py`
   - `standalone_tasks.py`
   - `standalone_uploader.py`
3. Run: `python standalone_upload.py`

**Note:** Both systems track uploads independently, so you can run both if needed.

### From Standalone to Prefect

1. Install Prefect: `pip install prefect>=3.0.0`
2. Start Prefect server: `prefect server start`
3. Create deployment: `python uploads.py`
4. Continue using Prefect normally

**Note:** Upload tracking won't transfer - each system maintains its own tracking.

## Performance Benchmarks

Based on typical AZUS uploads:

| Metric | Standalone | Prefect |
|--------|-----------|---------|
| 100 datasets, 10GB total | ~45 min | ~45 min |
| Memory usage | ~200 MB | ~350 MB |
| CPU usage | 5-10% | 10-15% |
| Log file size (100 uploads) | ~2 MB | ~5 MB |

*Upload time is the same because it's limited by network speed, not the tool.*

## Troubleshooting Comparison

### Problem: Upload Fails

**Standalone:**
```
1. Check console output for immediate error
2. Review azus_upload.log
3. Look at failed_results.csv
4. Error message tells you exactly what failed
```

**Prefect:**
```
1. Open dashboard
2. Click on failed flow run
3. View logs tab
4. Click on failed task for details
5. Check failed_results.csv
```

### Problem: Can't Connect to API

**Standalone:**
```
âŒ Upload failed: HTTP 401: Unauthorized
   Check INVENIO_RDM_ACCESS_TOKEN

# Quick fix:
source set_env.sh
python standalone_upload.py
```

**Prefect:**
```
Flow run fails with API error in logs

# Quick fix:
source set_env.sh
# Restart deployment via dashboard
```

## Recommendations by Team Size

### Solo Researcher
â†’ **Standalone** (simpler, less overhead)

### Small Team (2-5 people)
â†’ **Standalone** or **Prefect** (either works)
- Standalone if everyone comfortable with CLI
- Prefect if team wants visual dashboard

### Large Team (5+ people)
â†’ **Prefect** (better collaboration)
- Shared dashboard
- Better visibility
- Team can monitor each other's uploads

### Research Lab with IT Support
â†’ **Prefect** (professional setup)
- Can integrate with other workflows
- Better for production deployments
- IT team can maintain server

## Conclusion

**Both systems work equally well for uploads.**

Choose based on your preferences:
- **Simple & Direct** â†’ Standalone
- **Visual & Featured** â†’ Prefect

You can even use both:
- Standalone for quick ad-hoc uploads
- Prefect for scheduled/production runs

---

**Still not sure?** Start with **Standalone** - it's easier to set up and you can always switch to Prefect later if needed.
